{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02-topic-modelling-spiegel\n",
    "\n",
    "Calculate the topic distribution for every article in every week, over a range of years.\n",
    "So first I'll put all the documents together, then calculate the words-per-topic matrix, then run a long model, and finally produce the documents-per-topic matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from scipy.stats import entropy\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context(\"poster\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "sns.mpl.rc(\"figure\", figsize=(9,6))\n",
    "\n",
    "import warnings; warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    stopwords = set(nltk.corpus.stopwords.words('german'))\n",
    "    with open('data/german_stopwords.txt') as f:\n",
    "        more_stopwords = [ line[:-1] for line in f ]\n",
    "    stopwords = stopwords.union(set(more_stopwords))\n",
    "    \n",
    "    minlength = 3\n",
    "    \n",
    "    invalidChars = { '¡', '§', '©', '\\xad', '°', '²', '³', 'µ', '¹', '¿', '×', '\\u200b', \n",
    "                    '•', '‣', '…', '⁄', '₂', '€', '™', '▇', '■', '▶', '◆', '●', '★', '✽',\n",
    "                    '❏', '➝', '主', '原', '年', '後', '歸', '物', '舧', '舰'}\n",
    "    invalidChars = invalidChars.union(set(string.punctuation.replace(\"-\", \"–„“\")))\n",
    "    for token in nltk.word_tokenize(text):\n",
    "        t = token.lower()\n",
    "        if (len(t)<minlength) or (t in stopwords) or (t.replace('ß','ss') in stopwords) \\\n",
    "        or (t in string.punctuation) or (t[0] in string.punctuation) \\\n",
    "        or any(char in invalidChars for char in token):\n",
    "            continue\n",
    "        yield t\n",
    "        \n",
    "def normalise(vec):\n",
    "    return vec / np.dot(vec,vec)\n",
    "\n",
    "def combine_vectors(vectors):\n",
    "    return normalise(np.sum(vectors, axis=0))\n",
    "\n",
    "def important_words(vectorizer, vec, n):\n",
    "    return sorted(zip(vectorizer.get_feature_names(), vec), key=lambda x:x[1], reverse=True)[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(1947,2017)\n",
    "\n",
    "infiles = [ 'data/%d.csv' % d for d in years ]\n",
    "\n",
    "# create DataFrame for all articles\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for infile in infiles:\n",
    "\n",
    "    df_year = pd.read_csv(infile, index_col=0)\n",
    "    df_year = df_year[pd.notnull(df_year['text'])]\n",
    "\n",
    "    # uncomment for short run\n",
    "    #df = df.head(50)\n",
    "    \n",
    "    df = df.append(df_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3578, 308463)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_year), len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's estimate how long it's going to take.\n",
    "_________________________________\n",
    "\n",
    "25 topics (time in minutes)\n",
    "[\n",
    "[100, 0.24],\n",
    "[200, 0.42],\n",
    "[500, 0.66],\n",
    "[1000, 1.14],\n",
    "[2000, 2.10],\n",
    "[5000, 5.22]\n",
    "]\n",
    "\n",
    "Ok, from this I get that the time in minutes is:\n",
    "T = 0.1514 + 0.0010*n_documents\n",
    "\n",
    "\n",
    "- 10K documents               ->  10.15 minutes\n",
    "- 28178 (2009-2016) documents ->  28.32 minutes\n",
    "- 100K documents              ->  100.15 minutes (<2 hours)\n",
    "- 1M documents                ->  1000.15 minutes (~17 hours)\n",
    "_________________________________\n",
    "\n",
    "50 topics (time in minutes)\n",
    "[\n",
    "[100, 0.45],\n",
    "[200, 0.75],\n",
    "[500, 1.30],\n",
    "[1000, 2.23],\n",
    "[2000, 4.14],\n",
    "[5000, 9.77]\n",
    "]\n",
    "Ok, from this I get that the time in minutes is:\n",
    "T = 0.33 + 0.00189*n_documents\n",
    "\n",
    "- 10K documents               -> 19.23 minutes\n",
    "- 28178 (2009-2016) documents -> 53.59 minutes\n",
    "- 100K documents              -> 189.33 minutes (3 hours)\n",
    "- 1M documents                -> 1890.33 minutes (31.5 hours)\n",
    "_________________________________\n",
    "\n",
    "100 topics (time in minutes)\n",
    "[\n",
    "[100, 0.80],\n",
    "[200, 1.83],\n",
    "[500, 2.25],\n",
    "[1000, 4.51],\n",
    "[2000, 8.09],\n",
    "[5000, 18.97]\n",
    "]\n",
    "\n",
    "Ok, from this I get that the time in minutes is:\n",
    "T = 0.7077 + 0.003659*n_documents\n",
    "\n",
    "- 10K documents               ->  37 minutes\n",
    "- 28178 (2009-2016) documents ->  103 minutes (< 2 hours)\n",
    "- 100K documents              ->  366.61 minutes (6 hours)\n",
    "- 1M documents                ->  3659.70 minutes (2.5 days)\n",
    "\n",
    "_________________________________\n",
    "\n",
    "On the number of tokens:\n",
    "\n",
    "28178 documents:\n",
    "- n_topics=50, min_df=0.010, max_df=0.8: 5866 different tokens, total 6847730\n",
    "- n_topics=50, min_df=0.005, max_df=0.8: 10757 different tokens, total 8015999\n",
    "- n_topics=50, min_df=0.001, max_df=0.8: 37335 different tokens, total 9960130\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of document-term matrix (documents, tokens): (308463, 8041)\n",
      "Total number of tokens: 55589355\n",
      "85.26838853756587 minutes\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "start = time.time()\n",
    "\n",
    "# list of text documents\n",
    "text = df.text.values\n",
    "doc_ids = df.filename.values\n",
    "\n",
    "# create the transform\n",
    "vectorizer = CountVectorizer(tokenizer=tokenize, min_df=0.005, max_df=0.8)\n",
    "\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(text)\n",
    "\n",
    "# summarize\n",
    "#print(vectorizer.vocabulary_)\n",
    "\n",
    "# encode document-term matrix\n",
    "dtm = vectorizer.transform(text)\n",
    "\n",
    "# summarize encoded vector\n",
    "print('Shape of document-term matrix (documents, tokens):', dtm.shape)\n",
    "print('Total number of tokens:', dtm.sum() )\n",
    "#print(type(dtm))\n",
    "#print(dtm.toarray())\n",
    "\n",
    "end = time.time()\n",
    "print((end - start)/60.0,'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of document-term matrix (documents, tokens): (308463, 8041)\n",
      "Total number of tokens: 55589355\n",
      "85.27 minutes\n"
     ]
    }
   ],
   "source": [
    "# summarize encoded vector\n",
    "print('Shape of document-term matrix (documents, tokens):', dtm.shape)\n",
    "print('Total number of tokens:', dtm.sum() )\n",
    "#print(type(dtm))\n",
    "#print(dtm.toarray())\n",
    "\n",
    "end = time.time()\n",
    "print(round((end - start)/60.0,2),'minutes')\n",
    "\n",
    "from scipy.sparse import save_npz\n",
    "save_npz('data/dtm_matrix.npz', dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<308463x8041 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 41382887 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import load_npz\n",
    "dtm = load_npz('data/dtm_matrix.npz')\n",
    "\n",
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<308443x8041 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 41382887 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnz_per_row = dtm.getnnz(axis=1)\n",
    "non_null_rows = np.where(nnz_per_row > 0)[0]\n",
    "null_rows     = np.where(nnz_per_row <= 0)[0]\n",
    "\n",
    "dtm = dtm[dtm.getnnz(1)>0]\n",
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lda\n",
    "\n",
    "#n_topics = 30\n",
    "#n_topics = 50\n",
    "#n_topics = 70\n",
    "\n",
    "n_topics = 90\n",
    "\n",
    "topic_model = lda.LDA(n_topics=n_topics, n_iter=1500, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 308443\n",
      "INFO:lda:vocab_size: 8041\n",
      "INFO:lda:n_words: 55589355\n",
      "INFO:lda:n_topics: 90\n",
      "INFO:lda:n_iter: 1500\n",
      "INFO:lda:<0> log likelihood: -758086395\n",
      "INFO:lda:<10> log likelihood: -598041747\n",
      "INFO:lda:<20> log likelihood: -536046676\n",
      "INFO:lda:<30> log likelihood: -524010456\n",
      "INFO:lda:<40> log likelihood: -518544323\n",
      "INFO:lda:<50> log likelihood: -515508551\n",
      "INFO:lda:<60> log likelihood: -513485874\n",
      "INFO:lda:<70> log likelihood: -512084028\n",
      "INFO:lda:<80> log likelihood: -511049326\n",
      "INFO:lda:<90> log likelihood: -510263866\n",
      "INFO:lda:<100> log likelihood: -509665559\n",
      "INFO:lda:<110> log likelihood: -509174543\n",
      "INFO:lda:<120> log likelihood: -508799831\n",
      "INFO:lda:<130> log likelihood: -508469247\n",
      "INFO:lda:<140> log likelihood: -508154061\n",
      "INFO:lda:<150> log likelihood: -507904839\n",
      "INFO:lda:<160> log likelihood: -507691883\n",
      "INFO:lda:<170> log likelihood: -507526573\n",
      "INFO:lda:<180> log likelihood: -507373941\n",
      "INFO:lda:<190> log likelihood: -507228515\n",
      "INFO:lda:<200> log likelihood: -507109034\n",
      "INFO:lda:<210> log likelihood: -507001946\n",
      "INFO:lda:<220> log likelihood: -506902985\n",
      "INFO:lda:<230> log likelihood: -506821185\n",
      "INFO:lda:<240> log likelihood: -506726945\n",
      "INFO:lda:<250> log likelihood: -506636575\n",
      "INFO:lda:<260> log likelihood: -506566905\n",
      "INFO:lda:<270> log likelihood: -506498329\n",
      "INFO:lda:<280> log likelihood: -506436884\n",
      "INFO:lda:<290> log likelihood: -506381736\n",
      "INFO:lda:<300> log likelihood: -506318007\n",
      "INFO:lda:<310> log likelihood: -506270229\n",
      "INFO:lda:<320> log likelihood: -506233128\n",
      "INFO:lda:<330> log likelihood: -506178735\n",
      "INFO:lda:<340> log likelihood: -506137559\n",
      "INFO:lda:<350> log likelihood: -506107059\n",
      "INFO:lda:<360> log likelihood: -506076111\n",
      "INFO:lda:<370> log likelihood: -506023870\n",
      "INFO:lda:<380> log likelihood: -505967280\n",
      "INFO:lda:<390> log likelihood: -505970382\n",
      "INFO:lda:<400> log likelihood: -505951400\n",
      "INFO:lda:<410> log likelihood: -505930547\n",
      "INFO:lda:<420> log likelihood: -505891823\n",
      "INFO:lda:<430> log likelihood: -505874559\n",
      "INFO:lda:<440> log likelihood: -505851382\n",
      "INFO:lda:<450> log likelihood: -505824562\n",
      "INFO:lda:<460> log likelihood: -505794178\n",
      "INFO:lda:<470> log likelihood: -505777686\n",
      "INFO:lda:<480> log likelihood: -505744229\n",
      "INFO:lda:<490> log likelihood: -505727965\n",
      "INFO:lda:<500> log likelihood: -505695185\n",
      "INFO:lda:<510> log likelihood: -505690039\n",
      "INFO:lda:<520> log likelihood: -505657606\n",
      "INFO:lda:<530> log likelihood: -505660436\n",
      "INFO:lda:<540> log likelihood: -505603156\n",
      "INFO:lda:<550> log likelihood: -505609873\n",
      "INFO:lda:<560> log likelihood: -505575722\n",
      "INFO:lda:<570> log likelihood: -505563353\n",
      "INFO:lda:<580> log likelihood: -505560539\n",
      "INFO:lda:<590> log likelihood: -505540760\n",
      "INFO:lda:<600> log likelihood: -505538708\n",
      "INFO:lda:<610> log likelihood: -505525288\n",
      "INFO:lda:<620> log likelihood: -505484446\n",
      "INFO:lda:<630> log likelihood: -505509163\n",
      "INFO:lda:<640> log likelihood: -505478933\n",
      "INFO:lda:<650> log likelihood: -505490435\n",
      "INFO:lda:<660> log likelihood: -505485748\n",
      "INFO:lda:<670> log likelihood: -505465860\n",
      "INFO:lda:<680> log likelihood: -505450197\n",
      "INFO:lda:<690> log likelihood: -505428561\n",
      "INFO:lda:<700> log likelihood: -505432339\n",
      "INFO:lda:<710> log likelihood: -505458364\n",
      "INFO:lda:<720> log likelihood: -505432888\n",
      "INFO:lda:<730> log likelihood: -505431648\n",
      "INFO:lda:<740> log likelihood: -505419786\n",
      "INFO:lda:<750> log likelihood: -505423913\n",
      "INFO:lda:<760> log likelihood: -505435462\n",
      "INFO:lda:<770> log likelihood: -505394979\n",
      "INFO:lda:<780> log likelihood: -505410494\n",
      "INFO:lda:<790> log likelihood: -505411505\n",
      "INFO:lda:<800> log likelihood: -505416144\n",
      "INFO:lda:<810> log likelihood: -505401442\n",
      "INFO:lda:<820> log likelihood: -505413213\n",
      "INFO:lda:<830> log likelihood: -505391028\n",
      "INFO:lda:<840> log likelihood: -505411002\n",
      "INFO:lda:<850> log likelihood: -505403535\n",
      "INFO:lda:<860> log likelihood: -505405510\n",
      "INFO:lda:<870> log likelihood: -505399313\n",
      "INFO:lda:<880> log likelihood: -505429597\n",
      "INFO:lda:<890> log likelihood: -505421030\n",
      "INFO:lda:<900> log likelihood: -505396908\n",
      "INFO:lda:<910> log likelihood: -505405817\n",
      "INFO:lda:<920> log likelihood: -505383878\n",
      "INFO:lda:<930> log likelihood: -505372501\n",
      "INFO:lda:<940> log likelihood: -505384551\n",
      "INFO:lda:<950> log likelihood: -505369387\n",
      "INFO:lda:<960> log likelihood: -505367943\n",
      "INFO:lda:<970> log likelihood: -505371199\n",
      "INFO:lda:<980> log likelihood: -505353554\n",
      "INFO:lda:<990> log likelihood: -505337428\n",
      "INFO:lda:<1000> log likelihood: -505357432\n",
      "INFO:lda:<1010> log likelihood: -505371743\n",
      "INFO:lda:<1020> log likelihood: -505348451\n",
      "INFO:lda:<1030> log likelihood: -505336289\n",
      "INFO:lda:<1040> log likelihood: -505363790\n",
      "INFO:lda:<1050> log likelihood: -505352462\n",
      "INFO:lda:<1060> log likelihood: -505362483\n",
      "INFO:lda:<1070> log likelihood: -505364831\n",
      "INFO:lda:<1080> log likelihood: -505352636\n",
      "INFO:lda:<1090> log likelihood: -505337630\n",
      "INFO:lda:<1100> log likelihood: -505337933\n",
      "INFO:lda:<1110> log likelihood: -505316071\n",
      "INFO:lda:<1120> log likelihood: -505338887\n",
      "INFO:lda:<1130> log likelihood: -505321847\n",
      "INFO:lda:<1140> log likelihood: -505360358\n",
      "INFO:lda:<1150> log likelihood: -505342155\n",
      "INFO:lda:<1160> log likelihood: -505337913\n",
      "INFO:lda:<1170> log likelihood: -505310453\n",
      "INFO:lda:<1180> log likelihood: -505301267\n",
      "INFO:lda:<1190> log likelihood: -505308952\n",
      "INFO:lda:<1200> log likelihood: -505328297\n",
      "INFO:lda:<1210> log likelihood: -505333435\n",
      "INFO:lda:<1220> log likelihood: -505324148\n",
      "INFO:lda:<1230> log likelihood: -505318274\n",
      "INFO:lda:<1240> log likelihood: -505315816\n",
      "INFO:lda:<1250> log likelihood: -505321635\n",
      "INFO:lda:<1260> log likelihood: -505290791\n",
      "INFO:lda:<1270> log likelihood: -505316026\n",
      "INFO:lda:<1280> log likelihood: -505311462\n",
      "INFO:lda:<1290> log likelihood: -505330600\n",
      "INFO:lda:<1300> log likelihood: -505306248\n",
      "INFO:lda:<1310> log likelihood: -505277303\n",
      "INFO:lda:<1320> log likelihood: -505289931\n",
      "INFO:lda:<1330> log likelihood: -505292794\n",
      "INFO:lda:<1340> log likelihood: -505288607\n",
      "INFO:lda:<1350> log likelihood: -505288855\n",
      "INFO:lda:<1360> log likelihood: -505305839\n",
      "INFO:lda:<1370> log likelihood: -505313693\n",
      "INFO:lda:<1380> log likelihood: -505328628\n",
      "INFO:lda:<1390> log likelihood: -505284640\n",
      "INFO:lda:<1400> log likelihood: -505306817\n",
      "INFO:lda:<1410> log likelihood: -505315744\n",
      "INFO:lda:<1420> log likelihood: -505305579\n",
      "INFO:lda:<1430> log likelihood: -505338756\n",
      "INFO:lda:<1440> log likelihood: -505314088\n",
      "INFO:lda:<1450> log likelihood: -505317958\n",
      "INFO:lda:<1460> log likelihood: -505317563\n",
      "INFO:lda:<1470> log likelihood: -505314189\n",
      "INFO:lda:<1480> log likelihood: -505343245\n",
      "INFO:lda:<1490> log likelihood: -505332392\n",
      "INFO:lda:<1499> log likelihood: -505336409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148.4681915998458 minutes\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "document_topic_distributions = topic_model.fit_transform(dtm)\n",
    "\n",
    "end = time.time()\n",
    "print((end - start)/60.0,'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vectorizer.get_feature_names()\n",
    "topic_names = ['Topic %d'%k for k in range(1, n_topics + 1)]\n",
    "\n",
    "topic_word_distributions = pd.DataFrame(topic_model.components_, columns=vocab, index=topic_names)\n",
    "\n",
    "document_topic_distributions = pd.DataFrame(document_topic_distributions,\n",
    "                                            columns=topic_names,\n",
    "                                            index=doc_ids[non_null_rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_topic_distributions.to_csv('data/document_topic_distributions_'+str(n_topics)+'topics.csv')\n",
    "topic_word_distributions.to_csv('data/topic_word_distributions_'+str(n_topics)+'topics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "herr         0.014514\n",
       "frage        0.013728\n",
       "brief        0.010296\n",
       "herrn        0.009725\n",
       "fragen       0.006816\n",
       "könne        0.006811\n",
       "antwort      0.006206\n",
       "wissen       0.005848\n",
       "erklärung    0.005674\n",
       "sache        0.005607\n",
       "tage         0.005143\n",
       "rede         0.004489\n",
       "erklärt      0.004470\n",
       "oktober      0.004419\n",
       "schrieb      0.004390\n",
       "Name: Topic 2, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word_distributions.loc['Topic 2'].sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 4</th>\n",
       "      <th>Topic 5</th>\n",
       "      <th>Topic 6</th>\n",
       "      <th>Topic 7</th>\n",
       "      <th>Topic 8</th>\n",
       "      <th>Topic 9</th>\n",
       "      <th>Topic 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Topic 81</th>\n",
       "      <th>Topic 82</th>\n",
       "      <th>Topic 83</th>\n",
       "      <th>Topic 84</th>\n",
       "      <th>Topic 85</th>\n",
       "      <th>Topic 86</th>\n",
       "      <th>Topic 87</th>\n",
       "      <th>Topic 88</th>\n",
       "      <th>Topic 89</th>\n",
       "      <th>Topic 90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d-41122662</th>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.131250</td>\n",
       "      <td>0.068750</td>\n",
       "      <td>0.068750</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.068750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.006250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d-41122648</th>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d-41122673</th>\n",
       "      <td>0.047287</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.000775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d-41122667</th>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035652</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.000870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d-41122630</th>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.086122</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.004490</td>\n",
       "      <td>0.094286</td>\n",
       "      <td>0.135102</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.004490</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.037143</td>\n",
       "      <td>0.004490</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Topic 1   Topic 2   Topic 3   Topic 4   Topic 5   Topic 6  \\\n",
       "d-41122662  0.006250  0.006250  0.006250  0.131250  0.068750  0.068750   \n",
       "d-41122648  0.005000  0.005000  0.005000  0.005000  0.005000  0.005000   \n",
       "d-41122673  0.047287  0.000775  0.000775  0.008527  0.000775  0.000775   \n",
       "d-41122667  0.000870  0.000870  0.000870  0.000870  0.000870  0.000870   \n",
       "d-41122630  0.000408  0.086122  0.000408  0.000408  0.004490  0.094286   \n",
       "\n",
       "             Topic 7   Topic 8   Topic 9  Topic 10    ...     Topic 81  \\\n",
       "d-41122662  0.006250  0.006250  0.006250  0.068750    ...     0.006250   \n",
       "d-41122648  0.005000  0.005000  0.005000  0.005000    ...     0.005000   \n",
       "d-41122673  0.000775  0.000775  0.000775  0.008527    ...     0.000775   \n",
       "d-41122667  0.000870  0.000870  0.000870  0.000870    ...     0.035652   \n",
       "d-41122630  0.135102  0.000408  0.000408  0.000408    ...     0.000408   \n",
       "\n",
       "            Topic 82  Topic 83  Topic 84  Topic 85  Topic 86  Topic 87  \\\n",
       "d-41122662  0.006250  0.006250  0.006250  0.006250  0.006250  0.006250   \n",
       "d-41122648  0.005000  0.005000  0.005000  0.005000  0.005000  0.005000   \n",
       "d-41122673  0.000775  0.000775  0.000775  0.000775  0.000775  0.000775   \n",
       "d-41122667  0.000870  0.000870  0.000870  0.000870  0.000870  0.000870   \n",
       "d-41122630  0.000408  0.004490  0.000408  0.037143  0.004490  0.000408   \n",
       "\n",
       "            Topic 88  Topic 89  Topic 90  \n",
       "d-41122662  0.006250  0.006250  0.006250  \n",
       "d-41122648  0.005000  0.055000  0.005000  \n",
       "d-41122673  0.000775  0.000775  0.000775  \n",
       "d-41122667  0.000870  0.000870  0.000870  \n",
       "d-41122630  0.000408  0.000408  0.000408  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_topic_distributions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>00187</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>101</th>\n",
       "      <th>110</th>\n",
       "      <th>115</th>\n",
       "      <th>120</th>\n",
       "      <th>1200</th>\n",
       "      <th>125</th>\n",
       "      <th>...</th>\n",
       "      <th>überzeugt</th>\n",
       "      <th>überzeugte</th>\n",
       "      <th>überzeugung</th>\n",
       "      <th>überzogen</th>\n",
       "      <th>üblich</th>\n",
       "      <th>übliche</th>\n",
       "      <th>üblichen</th>\n",
       "      <th>übrigen</th>\n",
       "      <th>übt</th>\n",
       "      <th>übung</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic 1</th>\n",
       "      <td>1.269470e-08</td>\n",
       "      <td>1.269470e-08</td>\n",
       "      <td>1.269470e-08</td>\n",
       "      <td>1.269470e-08</td>\n",
       "      <td>1.269470e-08</td>\n",
       "      <td>1.269470e-08</td>\n",
       "      <td>1.269470e-08</td>\n",
       "      <td>1.269470e-08</td>\n",
       "      <td>1.269470e-08</td>\n",
       "      <td>1.269470e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>1.053787e-04</td>\n",
       "      <td>1.282165e-06</td>\n",
       "      <td>1.269470e-08</td>\n",
       "      <td>1.269470e-08</td>\n",
       "      <td>1.269470e-08</td>\n",
       "      <td>1.269470e-08</td>\n",
       "      <td>1.269470e-08</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>1.269470e-08</td>\n",
       "      <td>1.269470e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 2</th>\n",
       "      <td>1.099912e-08</td>\n",
       "      <td>1.099912e-08</td>\n",
       "      <td>1.099912e-08</td>\n",
       "      <td>1.099912e-08</td>\n",
       "      <td>1.099912e-08</td>\n",
       "      <td>1.099912e-08</td>\n",
       "      <td>1.099912e-08</td>\n",
       "      <td>1.099912e-08</td>\n",
       "      <td>1.099912e-08</td>\n",
       "      <td>1.099912e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>9.360364e-04</td>\n",
       "      <td>1.099912e-08</td>\n",
       "      <td>7.270530e-04</td>\n",
       "      <td>1.099912e-08</td>\n",
       "      <td>6.016630e-04</td>\n",
       "      <td>2.001950e-04</td>\n",
       "      <td>3.849803e-04</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>1.099912e-08</td>\n",
       "      <td>1.099912e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 3</th>\n",
       "      <td>5.949570e-03</td>\n",
       "      <td>1.725008e-08</td>\n",
       "      <td>2.803155e-03</td>\n",
       "      <td>5.261447e-04</td>\n",
       "      <td>1.725008e-08</td>\n",
       "      <td>3.053437e-04</td>\n",
       "      <td>2.001182e-04</td>\n",
       "      <td>5.916950e-04</td>\n",
       "      <td>1.725008e-08</td>\n",
       "      <td>2.846436e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.725008e-08</td>\n",
       "      <td>1.725008e-08</td>\n",
       "      <td>1.725008e-08</td>\n",
       "      <td>1.725008e-08</td>\n",
       "      <td>1.725008e-08</td>\n",
       "      <td>7.591761e-05</td>\n",
       "      <td>1.725008e-08</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>1.725008e-08</td>\n",
       "      <td>1.725008e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 4</th>\n",
       "      <td>1.315365e-08</td>\n",
       "      <td>1.315365e-08</td>\n",
       "      <td>1.315365e-08</td>\n",
       "      <td>2.959702e-04</td>\n",
       "      <td>1.315365e-08</td>\n",
       "      <td>1.315365e-08</td>\n",
       "      <td>1.315365e-08</td>\n",
       "      <td>1.315365e-08</td>\n",
       "      <td>1.315365e-08</td>\n",
       "      <td>1.315365e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>8.352698e-04</td>\n",
       "      <td>1.315365e-08</td>\n",
       "      <td>3.630538e-04</td>\n",
       "      <td>1.315365e-08</td>\n",
       "      <td>1.315365e-08</td>\n",
       "      <td>1.315365e-08</td>\n",
       "      <td>1.315365e-08</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>1.315365e-08</td>\n",
       "      <td>1.262882e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 5</th>\n",
       "      <td>1.078090e-02</td>\n",
       "      <td>1.816493e-08</td>\n",
       "      <td>9.627593e-04</td>\n",
       "      <td>8.210729e-04</td>\n",
       "      <td>1.816493e-08</td>\n",
       "      <td>1.816493e-08</td>\n",
       "      <td>3.651150e-06</td>\n",
       "      <td>2.089148e-04</td>\n",
       "      <td>3.487848e-04</td>\n",
       "      <td>3.453153e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.816493e-08</td>\n",
       "      <td>1.816493e-08</td>\n",
       "      <td>1.816493e-08</td>\n",
       "      <td>1.816493e-08</td>\n",
       "      <td>3.851146e-04</td>\n",
       "      <td>1.689520e-04</td>\n",
       "      <td>4.214445e-04</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>1.816493e-08</td>\n",
       "      <td>1.816493e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8041 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  000         00187           100          1000           101  \\\n",
       "Topic 1  1.269470e-08  1.269470e-08  1.269470e-08  1.269470e-08  1.269470e-08   \n",
       "Topic 2  1.099912e-08  1.099912e-08  1.099912e-08  1.099912e-08  1.099912e-08   \n",
       "Topic 3  5.949570e-03  1.725008e-08  2.803155e-03  5.261447e-04  1.725008e-08   \n",
       "Topic 4  1.315365e-08  1.315365e-08  1.315365e-08  2.959702e-04  1.315365e-08   \n",
       "Topic 5  1.078090e-02  1.816493e-08  9.627593e-04  8.210729e-04  1.816493e-08   \n",
       "\n",
       "                  110           115           120          1200           125  \\\n",
       "Topic 1  1.269470e-08  1.269470e-08  1.269470e-08  1.269470e-08  1.269470e-08   \n",
       "Topic 2  1.099912e-08  1.099912e-08  1.099912e-08  1.099912e-08  1.099912e-08   \n",
       "Topic 3  3.053437e-04  2.001182e-04  5.916950e-04  1.725008e-08  2.846436e-04   \n",
       "Topic 4  1.315365e-08  1.315365e-08  1.315365e-08  1.315365e-08  1.315365e-08   \n",
       "Topic 5  1.816493e-08  3.651150e-06  2.089148e-04  3.487848e-04  3.453153e-05   \n",
       "\n",
       "             ...          überzeugt    überzeugte   überzeugung     überzogen  \\\n",
       "Topic 1      ...       1.053787e-04  1.282165e-06  1.269470e-08  1.269470e-08   \n",
       "Topic 2      ...       9.360364e-04  1.099912e-08  7.270530e-04  1.099912e-08   \n",
       "Topic 3      ...       1.725008e-08  1.725008e-08  1.725008e-08  1.725008e-08   \n",
       "Topic 4      ...       8.352698e-04  1.315365e-08  3.630538e-04  1.315365e-08   \n",
       "Topic 5      ...       1.816493e-08  1.816493e-08  1.816493e-08  1.816493e-08   \n",
       "\n",
       "               üblich       übliche      üblichen   übrigen           übt  \\\n",
       "Topic 1  1.269470e-08  1.269470e-08  1.269470e-08  0.000301  1.269470e-08   \n",
       "Topic 2  6.016630e-04  2.001950e-04  3.849803e-04  0.001498  1.099912e-08   \n",
       "Topic 3  1.725008e-08  7.591761e-05  1.725008e-08  0.000854  1.725008e-08   \n",
       "Topic 4  1.315365e-08  1.315365e-08  1.315365e-08  0.000431  1.315365e-08   \n",
       "Topic 5  3.851146e-04  1.689520e-04  4.214445e-04  0.000797  1.816493e-08   \n",
       "\n",
       "                übung  \n",
       "Topic 1  1.269470e-08  \n",
       "Topic 2  1.099912e-08  \n",
       "Topic 3  1.725008e-08  \n",
       "Topic 4  1.262882e-04  \n",
       "Topic 5  1.816493e-08  \n",
       "\n",
       "[5 rows x 8041 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word_distributions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
